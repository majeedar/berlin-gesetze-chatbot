# Berlin Gesetze Chatbot

> RAG-based chatbot for Berlin laws and regulations using open-source tools

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

## ğŸ¯ Project Overview

An intelligent chatbot system that helps users navigate Berlin's legal documents using Retrieval-Augmented Generation (RAG). The system scrapes, processes, and indexes laws from [gesetze.berlin.de](https://gesetze.berlin.de) to provide accurate, context-aware answers.

### Key Features

- ğŸ” **Automated Scraping**: Collects laws and regulations from gesetze.berlin.de
- ğŸ“Š **Data Processing**: Cleans, chunks, and prepares documents for RAG
- ğŸ§® **Semantic Search**: Uses sentence-transformers for embeddings
- ğŸ’¾ **Vector Database**: ChromaDB for efficient similarity search
- ğŸ¤– **LLM Integration**: Groq API for fast, accurate responses
- ğŸ“¦ **PostgreSQL Storage**: Structured metadata and document storage
- ğŸ”„ **Apache Airflow**: Orchestrates data pipelines
- ğŸš€ **FastAPI Backend**: RESTful API for the chatbot
- ğŸ¨ **React Frontend**: User-friendly chat interface

## ï¿½ï¿½ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Frontend (React)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      API (FastAPI)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   RAG Pipeline                   â”‚
â”‚   â”œâ”€ Text Processor              â”‚
â”‚   â”œâ”€ Embedding Generator         â”‚
â”‚   â”œâ”€ Vector Store (ChromaDB)     â”‚
â”‚   â””â”€ LLM (Groq/Ollama)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚PostgreSQLâ”‚    â”‚ ChromaDB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Airflow    â”‚
â”‚  (Scraping)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- **OS**: Linux (Ubuntu 22.04+) or WSL2
- **RAM**: 16 GB minimum
- **Storage**: 50 GB free space
- **Software**:
  - Docker & Docker Compose
  - Python 3.10+
  - Git
  - Node.js 18+ (for frontend)

## ğŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/majeedar/berlin-gesetze-chatbot.git
cd berlin-gesetze-chatbot
```

### 2. Setup Environment
```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy environment template
cp .env.example .env

# Edit .env and add your API keys
nano .env
```

### 3. Start Services
```bash
# Start PostgreSQL, Redis, ChromaDB
make start

# Or manually with docker-compose
docker compose up -d postgres redis chromadb
```

### 4. Run Initial Scraping
```bash
# Open Jupyter notebook
jupyter notebook notebooks/gesetze_scraping_complete.ipynb

# Or run with Airflow
make phase1
```

### 5. Test RAG System
```bash
# Open RAG testing notebook
jupyter notebook notebooks/rag-testing/test_rag_prototype.ipynb
```

## ğŸ“ Project Structure
```
berlin-gesetze-chatbot/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ rag/                      # RAG pipeline modules
â”‚   â”‚   â”œâ”€â”€ text_processor.py    # Text chunking
â”‚   â”‚   â”œâ”€â”€ embeddings.py        # Embedding generation
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB interface
â”‚   â”‚   â””â”€â”€ rag_pipeline.py      # Complete pipeline
â”‚   â”œâ”€â”€ database/                 # Database utilities
â”‚   â”œâ”€â”€ api/                      # FastAPI backend
â”‚   â””â”€â”€ utils/                    # Helper functions
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ gesetze_scraping_complete.ipynb
â”‚   â””â”€â”€ rag-testing/
â”‚       â””â”€â”€ test_rag_prototype.ipynb
â”‚
â”œâ”€â”€ airflow/                      # Airflow DAGs
â”‚   â””â”€â”€ dags/
â”‚
â”œâ”€â”€ services/                     # Microservices
â”‚   â”œâ”€â”€ api/                      # Backend API
â”‚   â””â”€â”€ frontend/                 # React UI
â”‚
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ rag_config.yaml
â”‚   â””â”€â”€ models.yaml
â”‚
â”œâ”€â”€ data/                         # Data storage
â”‚   â”œâ”€â”€ raw/                      # Scraped documents
â”‚   â”œâ”€â”€ processed/                # Processed chunks
â”‚   â””â”€â”€ embeddings/               # Vector embeddings
â”‚
â”œâ”€â”€ docker-compose.yml            # Docker services
â”œâ”€â”€ Makefile                      # Development commands
â””â”€â”€ requirements.txt              # Python dependencies
```

## ğŸ› ï¸ Technology Stack

### Core Technologies

- **Python 3.10+**: Main programming language
- **Docker**: Containerization
- **PostgreSQL**: Relational database
- **ChromaDB**: Vector database
- **Redis**: Caching layer

### Data Pipeline

- **Apache Airflow**: Workflow orchestration
- **BeautifulSoup4**: Web scraping
- **Pandas**: Data processing

### RAG Components

- **sentence-transformers**: Text embeddings
- **LangChain**: RAG framework
- **Groq API**: LLM inference (Llama 3.1)
- **Ollama**: Local LLM alternative

### API & Frontend

- **FastAPI**: REST API backend
- **React**: Frontend framework
- **Nginx**: Web server

## ğŸ“– Usage

### Makefile Commands
```bash
# Setup
make setup              # Initial project setup

# Development phases
make phase1             # Start data collection (Airflow)
make phase2             # Data processing
make phase3             # Generate embeddings
make phase4             # Test API
make phase5             # Full stack

# Service management
make start              # Start core services
make stop               # Stop all services
make logs               # View logs
make stats              # Resource usage

# Database
make db-shell           # PostgreSQL shell
make redis-cli          # Redis CLI

# Cleanup
make clean              # Remove all data
```

### Example Queries
```python
from src.rag.rag_pipeline import RAGPipeline
import yaml

# Load configuration
with open('config/rag_config.yaml') as f:
    config = yaml.safe_load(f)

# Initialize RAG
rag = RAGPipeline(config)

# Query
result = rag.query("Was regelt das Berliner Bauordnungsrecht?")
print(result['answer'])
```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file with:
```bash
# Database
POSTGRES_USER=gesetze
POSTGRES_PASSWORD=your_password
POSTGRES_DB=gesetze

# LLM API (Groq)
LLM_PROVIDER=groq
LLM_API_KEY=your_groq_api_key
LLM_MODEL=llama-3.1-8b-instant

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Vector Database
CHROMA_HOST=localhost
CHROMA_PORT=8000
```

### RAG Configuration

Edit `config/rag_config.yaml`:
```yaml
chunking:
  chunk_size: 500      # Adjust chunk size
  chunk_overlap: 50

retrieval:
  top_k: 5             # Number of documents to retrieve
  score_threshold: 0.7

llm:
  temperature: 0.7     # LLM creativity
  max_tokens: 2048
```

## ğŸ“Š Data Pipeline

1. **Scraping**: Collects laws from gesetze.berlin.de
2. **Processing**: Cleans and normalizes text
3. **Chunking**: Splits documents into manageable pieces
4. **Embedding**: Generates vector representations
5. **Indexing**: Stores in ChromaDB
6. **Retrieval**: Finds relevant chunks for queries
7. **Generation**: Uses LLM to create answers

## ğŸ§ª Testing
```bash
# Run unit tests
pytest tests/

# Test specific module
pytest tests/test_rag_pipeline.py

# Run with coverage
pytest --cov=src tests/
```

## ğŸ“ˆ Performance

- **Embedding Speed**: ~100 docs/second on CPU
- **Retrieval Latency**: <100ms for top-5 results
- **LLM Response Time**: 1-3 seconds (with Groq)
- **Memory Usage**: 4-6 GB RAM (without local LLM)

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- Berlin Senate for providing open access to legal documents
- Anthropic for Claude AI assistance
- Open-source community for amazing tools

## ğŸ“§ Contact

**Majeed** - [@majeedar](https://github.com/majeedar)

**Project Link**: [https://github.com/majeedar/berlin-gesetze-chatbot](https://github.com/majeedar/berlin-gesetze-chatbot)

## ğŸ—ºï¸ Roadmap

- [x] Web scraping pipeline
- [x] Document processing
- [x] RAG prototype
- [ ] FastAPI endpoints
- [ ] React frontend
- [ ] User authentication
- [ ] Deployment scripts
- [ ] Performance optimization
- [ ] Multi-language support
- [ ] Mobile app

## âš ï¸ Disclaimer

This tool is for educational and research purposes. Always verify legal information with official sources.

---

**Built with â¤ï¸ for the Berlin tech community**
